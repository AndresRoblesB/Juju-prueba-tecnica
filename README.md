# ETL-TEST

Pipeline ETL para procesamiento de datos de Ã³rdenes, productos y usuarios.

## ğŸ“‹ Requisitos Previos

- Python 3.11 o superior (Se realizÃ³ con 3.14, este serÃ­a el recomendado)
- pip (gestor de paquetes de Python)

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n (Windows sin Docker)

### 1. Clonar el repositorio

```bash
git clone https://github.com/AndresRoblesB/Juju-prueba-tecnica.git
```

### 2. Crear entorno virtual

```bash
python -m venv .venv
```

### 3. Activar el entorno virtual

```bash
Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
.venv\Scripts\activate
```

### 4. Instalar dependencias

```bash
pip install -r requirements.txt
```

## ğŸ’» Uso

### Ejecutar el pipeline ETL

El pipeline acepta un parÃ¡metro de fecha opcional en formato `YYYY-MM-DD` para filtrar las Ã³rdenes desde esa fecha.

#### OpciÃ³n 1: Con fecha especÃ­fica

```bash
python -m src.etl_job 2025-08-20
```

#### OpciÃ³n 2: Sin parÃ¡metros (usa fecha por defecto)

```bash
python -m src.etl_job
```

### Resultado

El pipeline ejecutarÃ¡ las siguientes etapas:

1. **ExtracciÃ³n**: Lee datos de `sample_data/` y los mueve a `output/raw/`
   - `raw_orders.parquet`
   - `raw_products.parquet`
   - `raw_users.parquet`

2. **TransformaciÃ³n**: Procesa los datos y genera archivos curados en `output/curated/`
   - Datos procesados y limpios listos para anÃ¡lisis

## ğŸ“ Estructura del Proyecto

```
JUJU-PRUEBA-TECNICA/
â”œâ”€â”€ .venv/                  # Entorno virtual (no incluido en git)
â”œâ”€â”€ docs/                   # DocumentaciÃ³n
â”œâ”€â”€ output/                 # Datos procesados
â”‚   â”œâ”€â”€ raw/               # Datos extraÃ­dos
â”‚   â””â”€â”€ curated/           # Datos transformados
â”œâ”€â”€ sample_data/           # Datos de ejemplo
â”œâ”€â”€ sql/                   # Scripts SQL (No se usÃ³ en este caso)
â”œâ”€â”€ src/                   # CÃ³digo fuente
â”‚   â”œâ”€â”€ api_client.py     # Cliente para extracciÃ³n de datos
â”‚   â”œâ”€â”€ db.py             # Funciones de base de datos (No se usÃ³ en este caso)
â”‚   â”œâ”€â”€ etl_job.py        # Pipeline principal
â”‚   â””â”€â”€ transforms.py     # Transformaciones de datos
â”œâ”€â”€ tests/                 # Tests unitarios
â”œâ”€â”€ requirements.txt       # Dependencias del proyecto
â””â”€â”€ README.md             # Este archivo
```

## ğŸ§ª Ejecutar Tests

```bash
pytest tests/test_transforms.py
```

## ğŸ“¦ Dependencias Principales

- **pandas** (2.3.3): ManipulaciÃ³n y anÃ¡lisis de datos
- **pyarrow** (22.0.0): Lectura/escritura de archivos Parquet
- **pytest** (9.0.2): Framework de testing

## ğŸ”§ Desactivar el entorno virtual

Cuando termines de trabajar:

```bash
deactivate
```

## ğŸ“ Notas

- Los archivos de salida se generan en formato Parquet para optimizar el almacenamiento y la velocidad de lectura
- AsegÃºrate de tener el entorno virtual activado antes de ejecutar el pipeline

## ğŸ³ Docker (Opcional)

Si prefieres usar Docker, consulta el archivo `docker-compose.yml` en el repositorio y corre los siguientes comandos

```bash
docker compose build
```

```bash
docker compose run --rm etl python -m src.etl_job 2025-08-20
```


.

---

**Proyecto JUJU-PRUEBA-TECNICA** | Procesamiento eficiente de datos
